import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
import cv2  # ç”¨äºå¤„ç†è‡ªå®šä¹‰å›¾åƒ

# å¯ç”¨ Keras åç«¯
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)

# --- 1. æ•°æ®é›†åŠ è½½ä¸é¢„å¤„ç† ---


def load_and_preprocess_data():
    """åŠ è½½ MNIST æ•°æ®é›†å¹¶è¿›è¡Œé¢„å¤„ç†"""
    print("--- 1. æ•°æ®é›†åŠ è½½ä¸é¢„å¤„ç† ---")
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    # å½’ä¸€åŒ– (å°†åƒç´ å€¼ä» 0-255 ç¼©æ”¾åˆ° 0-1)
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0

    # æ ‡ç­¾ç‹¬çƒ­ç¼–ç  (One-Hot Encoding)
    # 5 -> [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]
    y_train = to_categorical(y_train, num_classes=10)
    y_test = to_categorical(y_test, num_classes=10)

    # æ³¨æ„ï¼šBP/MLP éœ€è¦å±•å¹³(Flatten)è¾“å…¥ï¼ŒKeras çš„ Flatten å±‚å¯ä»¥è‡ªåŠ¨å®Œæˆ
    
    print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶ (X): {x_train.shape}")
    print(f"è®­ç»ƒæ ‡ç­¾å½¢çŠ¶ (Y): {y_train.shape}")
    
    return x_train, y_train, x_test, y_test

# --- 2. BP ç¥ç»ç½‘ç»œæ¨¡å‹æ„å»º ---


def build_bp_model(input_shape):
    """æ„å»º BP ç¥ç»ç½‘ç»œ (MLP) æ¨¡å‹"""
    print("--- 2. BP ç¥ç»ç½‘ç»œæ¨¡å‹æ„å»º ---")
    model = Sequential([
        # å±•å¹³å±‚ï¼šå°† 28x28 å›¾åƒè¾“å…¥è½¬æ¢ä¸º 784 ç»´å‘é‡
        Flatten(input_shape=input_shape), 
        
        # éšè—å±‚ 1: 512 ä¸ªç¥ç»å…ƒï¼Œä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°
        Dense(512, activation='relu'), 
        
        # éšè—å±‚ 2: 256 ä¸ªç¥ç»å…ƒï¼Œä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°
        Dense(256, activation='relu'), 
        
        # è¾“å‡ºå±‚: 10 ä¸ªç¥ç»å…ƒ (å¯¹åº” 0-9 åä¸ªç±»åˆ«), ä½¿ç”¨ Softmax æ¿€æ´»å‡½æ•°è¿›è¡Œæ¦‚ç‡è¾“å‡º
        Dense(10, activation='softmax') 
    ])

    # ç¼–è¯‘æ¨¡å‹ï¼š
    # ä¼˜åŒ–å™¨: Adam (é«˜æ•ˆçš„æ¢¯åº¦ä¸‹é™å˜ä½“)
    # æŸå¤±å‡½æ•°: Categorical Crossentropy (é€‚ç”¨äº One-Hot ç¼–ç çš„åˆ†ç±»é—®é¢˜)
    # è¯„ä¼°æŒ‡æ ‡: å‡†ç¡®ç‡ (Accuracy)
    model.compile(optimizer='adam',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    model.summary()
    return model

# --- 3. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼° ---


def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, 
                             epochs=10, batch_size=128):
    """è®­ç»ƒæ¨¡å‹å¹¶è¯„ä¼°æ€§èƒ½"""
    print("--- 3. æ¨¡å‹è®­ç»ƒä¸è¯„ä¼° ---")
    
    # è®­ç»ƒæ¨¡å‹
    history = model.fit(x_train, y_train,
                        epochs=epochs,
                        batch_size=batch_size,
                        validation_data=(x_test, y_test),
                        verbose=1)

    # è¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½
    loss, acc = model.evaluate(x_test, y_test, verbose=0)
    print("\n--- è¯„ä¼°ç»“æœ ---")
    print(f"æµ‹è¯•é›†æŸå¤± (Loss): {loss:.4f}")
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡ (Accuracy): {acc*100:.2f}%")
    
    return history

# --- 4. è¯†åˆ«ä½ æ‰‹å†™çš„æ•°å­— (æ ¸å¿ƒè¦æ±‚) ---


def preprocess_custom_image(image_path):
    """
    é¢„å¤„ç†å•ä¸ªè‡ªå®šä¹‰æ‰‹å†™æ•°å­—å›¾åƒï¼Œä½¿å…¶ä¸ MNIST æ ¼å¼å…¼å®¹ã€‚
    1. è¯»å…¥ç°åº¦å›¾ã€‚
    2. ç¼©æ”¾è‡³ 28x28ã€‚
    3. åè‰²å¤„ç† (MNIST ç¬”ç”»ä¸ºç™½è‰²ï¼ŒèƒŒæ™¯ä¸ºé»‘è‰²)ã€‚
    4. å½’ä¸€åŒ–ã€‚
    """
    # è¯»å…¥ç°åº¦å›¾
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise FileNotFoundError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")

    # ç¡®ä¿èƒŒæ™¯æ˜¯ç™½è‰²ï¼Œç¬”ç”»æ˜¯é»‘è‰² (åè‰²å¤„ç†ï¼Œä½¿å…¶ä¸ MNIST å…¼å®¹)
    # å‡è®¾ä½ çš„æ‰‹å†™å›¾æ˜¯ç™½åº•é»‘å­—ï¼Œéœ€è¦åè½¬ä¸ºé»‘åº•ç™½å­—
    img = cv2.bitwise_not(img)
    
    # ç¼©æ”¾è‡³ 28x28
    img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)

    # å½’ä¸€åŒ–å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
    img = img.astype('float32') / 255.0

    # ç¡®ä¿èƒŒæ™¯è¶³å¤Ÿé»‘ (æ¥è¿‘ 0)ï¼Œå‰æ™¯è¶³å¤Ÿäº® (æ¥è¿‘ 1)
    # å¯ä»¥é€‰æ‹©æ€§åœ°æ·»åŠ é˜ˆå€¼å¤„ç† (å¯é€‰)
    # _, img = cv2.threshold(img, 0.1, 1.0, cv2.THRESH_BINARY) 

    # Keras éœ€è¦ (Batch_Size, Height, Width) çš„è¾“å…¥å½¢çŠ¶ï¼Œè¿™é‡Œæ˜¯ (1, 28, 28)
    return np.expand_dims(img, axis=0) 


def test_custom_numbers(model):
    """
    æµ‹è¯•ä½ æ‰‹å†™çš„ 10 ä¸ªæ•°å­— (0-9)ã€‚
    ä½ éœ€è¦åˆ›å»º 10 ä¸ªå›¾åƒæ–‡ä»¶ï¼Œä¾‹å¦‚ '0.png', '1.png', ..., '9.png'ï¼Œ
    å¹¶ç¡®ä¿å®ƒä»¬ä½äºå½“å‰ç›®å½•ä¸‹ï¼Œä¸”æ˜¯é»‘ç™½æ‰‹å†™æ•°å­—ã€‚
    """
    print("\n--- 4. è¯†åˆ«ä½ æ‰‹å†™çš„æ•°å­— ---")
    custom_results = {}
    
    # å®šä¹‰ 10 ä¸ªè‡ªå®šä¹‰å›¾åƒçš„æ–‡ä»¶å
    image_names = [f"{i}.png" for i in range(10)] 

    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
    axes = axes.flatten()

    for i, name in enumerate(image_names):
        try:
            # é¢„å¤„ç†å›¾åƒ
            custom_img_processed = preprocess_custom_image(name)
            
            # æ¨¡å‹é¢„æµ‹
            prediction = model.predict(custom_img_processed, verbose=0)
            predicted_class = np.argmax(prediction)
            confidence = np.max(prediction) * 100
            
            # è®°å½•ç»“æœ
            result_str = f"prediction: {predicted_class} ({confidence:.2f}%)"
            is_correct = predicted_class == i
            custom_results[i] = (result_str, is_correct)
            
            # ç»˜å›¾å±•ç¤º
            ax = axes[i]
            # ç§»é™¤æ‰¹æ¬¡ç»´åº¦ï¼Œæ˜¾ç¤º 28x28 å›¾åƒ
            ax.imshow(custom_img_processed[0], cmap='gray') 
            ax.set_title(f"Target: {i}\n{result_str}", 
                         color='green' if is_correct else 'red')
            ax.axis('off')

        except FileNotFoundError:
            print(f"â— è­¦å‘Š: ç¼ºå°‘æ–‡ä»¶ {name}ã€‚è¯·åˆ›å»º 10 ä¸ªæ‰‹å†™æ•°å­—å›¾åƒæ–‡ä»¶ (0.png - 9.png)ã€‚")
            custom_results[i] = ("æ–‡ä»¶ç¼ºå¤±", False)
            axes[i].set_title(f"Target: {i}\næ–‡ä»¶ç¼ºå¤±", color='blue')
            axes[i].axis('off')
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {name} æ—¶å‡ºé”™: {e}")
            custom_results[i] = (f"å¤„ç†é”™è¯¯: {e}", False)
            axes[i].set_title(f"Target: {i}\nå¤„ç†é”™è¯¯", color='red')
            axes[i].axis('off')
    
    plt.tight_layout()
    plt.show()

    # æ€»ç»“è¯†åˆ«ç»“æœ
    print("\n--- è¯†åˆ«ç»“æœæ€»ç»“ ---")
    all_correct = True
    for target, (result_str, is_correct) in custom_results.items():
        if not is_correct:
            all_correct = False
            print(f"âŒ ç›®æ ‡ {target}: {result_str}")
        else:
            print(f"âœ… ç›®æ ‡ {target}: {result_str}")
    
    if all_correct:
        print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰ 10 ä¸ªæ‰‹å†™æ•°å­—å‡è¢«æ­£ç¡®è¯†åˆ«ã€‚")
    else:
        print("\nâš ï¸ è‡³å°‘æœ‰ä¸€ä¸ªæ•°å­—è¯†åˆ«é”™è¯¯ã€‚å¯èƒ½éœ€è¦è°ƒæ•´å›¾åƒé¢„å¤„ç†æˆ–é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚")

# --- ä¸»ç¨‹åºå…¥å£ ---


if __name__ == '__main__':
    # 1. æ•°æ®é›†åŠ è½½
    x_train, y_train, x_test, y_test = load_and_preprocess_data()
    
    # 2. æ¨¡å‹æ„å»º
    # è¾“å…¥å½¢çŠ¶æ˜¯ (28, 28)
    model = build_bp_model(x_train.shape[1:]) 
    
    # 3. æ¨¡å‹è®­ç»ƒ
    # æ¨èä½¿ç”¨ 10-20 ä¸ª Epochs
    train_and_evaluate_model(model, x_train, y_train, x_test, y_test, 
                             epochs=10) 
    
    # 4. æµ‹è¯•è‡ªå®šä¹‰æ‰‹å†™æ•°å­—
    test_custom_numbers(model)